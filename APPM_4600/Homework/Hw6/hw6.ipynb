{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a937d2c8-e558-40fa-a673-84761e86e1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random as rand\n",
    "import time\n",
    "import math\n",
    "from scipy import io, integrate, linalg, signal\n",
    "from scipy.linalg import lu_factor, lu_solve\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML, Video\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34feb5bc-8eea-4280-9546-f42f3ab2c402",
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_method_nd(f,Jf,x0,tol,nmax,verb=False):\n",
    "\n",
    "    # Initialize arrays and function value\n",
    "    xn = x0; #initial guess\n",
    "    rn = x0; #list of iterates\n",
    "    Fn = f(xn); #function value vector\n",
    "    n=0;\n",
    "    nf=1; nJ=0; #function and Jacobian evals\n",
    "    npn=1;\n",
    "\n",
    "    if verb:\n",
    "        print(\"|--n--|----xn----|---|f(xn)|---|\");\n",
    "\n",
    "    while npn>tol and n<=nmax:\n",
    "        # compute n x n Jacobian matrix\n",
    "        Jn = Jf(xn);\n",
    "        nJ+=1;\n",
    "\n",
    "        if verb:\n",
    "            print(\"|--%d--|%1.7f|%1.12f|\" %(n,np.linalg.norm(xn),np.linalg.norm(Fn)));\n",
    "\n",
    "        # Newton step (we could check whether Jn is close to singular here)\n",
    "        pn = -np.linalg.solve(Jn,Fn);\n",
    "        xn = xn + pn;\n",
    "        npn = np.linalg.norm(pn); #size of Newton step\n",
    "\n",
    "        n+=1;\n",
    "        rn = np.vstack((rn,xn));\n",
    "        Fn = f(xn);\n",
    "        nf+=1;\n",
    "\n",
    "    r=xn;\n",
    "\n",
    "    if verb:\n",
    "        if np.linalg.norm(Fn)>tol:\n",
    "            print(\"Newton method failed to converge, n=%d, |F(xn)|=%1.1e\\n\" % (nmax,np.linalg.norm(Fn)));\n",
    "        else:\n",
    "            print(\"Newton method converged, n=%d, |F(xn)|=%1.1e\\n\" % (n,np.linalg.norm(Fn)));\n",
    "\n",
    "    return (r,rn,nf,nJ);\n",
    "\n",
    "# Lazy Newton method (chord iteration) in n dimensions implementation\n",
    "def lazy_newton_method_nd(f,Jf,x0,tol,nmax,verb=False):\n",
    "\n",
    "    # Initialize arrays and function value\n",
    "    xn = x0; #initial guess\n",
    "    rn = x0; #list of iterates\n",
    "    Fn = f(xn); #function value vector\n",
    "    # compute n x n Jacobian matrix (ONLY ONCE)\n",
    "    Jn = Jf(xn);\n",
    "\n",
    "    # Use pivoted LU factorization to solve systems for Jf. Makes lusolve O(n^2)\n",
    "    lu, piv = lu_factor(Jn);\n",
    "\n",
    "    n=0;\n",
    "    nf=1; nJ=1; #function and Jacobian evals\n",
    "    npn=1;\n",
    "\n",
    "    if verb:\n",
    "        print(\"|--n--|----xn----|---|f(xn)|---|\");\n",
    "\n",
    "    while npn>tol and n<=nmax:\n",
    "\n",
    "        if verb:\n",
    "            print(\"|--%d--|%1.7f|%1.12f|\" %(n,np.linalg.norm(xn),np.linalg.norm(Fn)));\n",
    "\n",
    "        # Newton step (we could check whether Jn is close to singular here)\n",
    "        pn = -lu_solve((lu, piv), Fn); #We use lu solve instead of pn = -np.linalg.solve(Jn,Fn);\n",
    "        xn = xn + pn;\n",
    "        npn = np.linalg.norm(pn); #size of Newton step\n",
    "\n",
    "        n+=1;\n",
    "        rn = np.vstack((rn,xn));\n",
    "        Fn = f(xn);\n",
    "        nf+=1;\n",
    "\n",
    "    r=xn;\n",
    "\n",
    "    if verb:\n",
    "        if np.linalg.norm(Fn)>tol:\n",
    "            print(\"Lazy Newton method failed to converge, n=%d, |F(xn)|=%1.1e\\n\" % (nmax,np.linalg.norm(Fn)));\n",
    "        else:\n",
    "            print(\"Lazy Newton method converged, n=%d, |F(xn)|=%1.1e\\n\" % (n,np.linalg.norm(Fn)));\n",
    "\n",
    "    return (r,rn,nf,nJ);\n",
    "\n",
    "# Implementation of Broyden method. B0 can either be an approx of Jf(x0) (Bmat='fwd'),\n",
    "# an approx of its inverse (Bmat='inv') or the identity (Bmat='Id')\n",
    "def broyden_method_nd(f,B0,x0,tol,nmax,Bmat='Id',verb=False):\n",
    "\n",
    "    # Initialize arrays and function value\n",
    "    d = x0.shape[0];\n",
    "    xn = x0; #initial guess\n",
    "    rn = x0; #list of iterates\n",
    "    Fn = f(xn); #function value vector\n",
    "    n=0;\n",
    "    nf=1;\n",
    "    npn=1;\n",
    "\n",
    "    #####################################################################\n",
    "    # Create functions to apply B0 or its inverse\n",
    "    if Bmat=='fwd':\n",
    "        #B0 is an approximation of Jf(x0)\n",
    "        # Use pivoted LU factorization to solve systems for B0. Makes lusolve O(n^2)\n",
    "        lu, piv = lu_factor(B0);\n",
    "        luT, pivT = lu_factor(B0.T);\n",
    "\n",
    "        def Bapp(x): return lu_solve((lu, piv), x); #np.linalg.solve(B0,x);\n",
    "        def BTapp(x): return lu_solve((luT, pivT), x) #np.linalg.solve(B0.T,x);\n",
    "    elif Bmat=='inv':\n",
    "        #B0 is an approximation of the inverse of Jf(x0)\n",
    "        def Bapp(x): return B0 @ x;\n",
    "        def BTapp(x): return B0.T @ x;\n",
    "    else:\n",
    "        Bmat='Id';\n",
    "        #default is the identity\n",
    "        def Bapp(x): return x;\n",
    "        def BTapp(x): return x;\n",
    "    ####################################################################\n",
    "    # Define function that applies Bapp(x)+Un*Vn.T*x depending on inputs\n",
    "    def Inapp(Bapp,Bmat,Un,Vn,x):\n",
    "        rk=Un.shape[0];\n",
    "\n",
    "        if Bmat=='Id':\n",
    "            y=x;\n",
    "        else:\n",
    "            y=Bapp(x);\n",
    "\n",
    "        if rk>0:\n",
    "            y=y+Un.T@(Vn@x);\n",
    "\n",
    "        return y;\n",
    "    #####################################################################\n",
    "\n",
    "    # Initialize low rank matrices Un and Vn\n",
    "    Un = np.zeros((0,d)); Vn=Un;\n",
    "\n",
    "    if verb:\n",
    "        print(\"|--n--|----xn----|---|f(xn)|---|\");\n",
    "\n",
    "    while npn>tol and n<=nmax:\n",
    "        if verb:\n",
    "            print(\"|--%d--|%1.7f|%1.12f|\" % (n,np.linalg.norm(xn),np.linalg.norm(Fn)));\n",
    "\n",
    "        #Broyden step xn = xn -B_n\\Fn\n",
    "        dn = -Inapp(Bapp,Bmat,Un,Vn,Fn);\n",
    "        # Update xn\n",
    "        xn = xn + dn;\n",
    "        npn=np.linalg.norm(dn);\n",
    "\n",
    "        ###########################################################\n",
    "        ###########################################################\n",
    "        # Update In using only the previous I_n-1\n",
    "        #(this is equivalent to the explicit update formula)\n",
    "        Fn1 = f(xn);\n",
    "        dFn = Fn1-Fn;\n",
    "        nf+=1;\n",
    "        I0rn = Inapp(Bapp,Bmat,Un,Vn,dFn); #In^{-1}*(Fn+1 - Fn)\n",
    "        un = dn - I0rn;                    #un = dn - In^{-1}*dFn\n",
    "        cn = dn.T @ (I0rn);                # We divide un by dn^T In^{-1}*dFn\n",
    "        # The end goal is to add the rank 1 u*v' update as the next columns of\n",
    "        # Vn and Un, as is done in, say, the eigendecomposition\n",
    "        Vn = np.vstack((Vn,Inapp(BTapp,Bmat,Vn,Un,dn)));\n",
    "        Un = np.vstack((Un,(1/cn)*un));\n",
    "\n",
    "        n+=1;\n",
    "        Fn=Fn1;\n",
    "        rn = np.vstack((rn,xn));\n",
    "\n",
    "    r=xn;\n",
    "\n",
    "    if verb:\n",
    "        if npn>tol:\n",
    "            print(\"Broyden method failed to converge, n=%d, |F(xn)|=%1.1e\\n\" % (nmax,np.linalg.norm(Fn)));\n",
    "        else:\n",
    "            print(\"Broyden method converged, n=%d, |F(xn)|=%1.1e\\n\" % (n,np.linalg.norm(Fn)));\n",
    "\n",
    "    return(r,rn,nf)\n",
    "\n",
    "def LS_Gw(f,xn,Fn,dn,nf,eps,maxbis,verb,LS):\n",
    "    #Derivative-free linesearch for rootfinding\n",
    "    #Newton and Quasi-Newton methods (Griewank LS method)\n",
    "\n",
    "    # Begin line search. Evaluate Fn at full step\n",
    "    Fnp = f(xn+dn);\n",
    "    nf+=1;\n",
    "    beta=1;\n",
    "    ndn = np.linalg.norm(dn);\n",
    "\n",
    "    if (LS and ndn > 1e-10):\n",
    "        dFn = Fnp-Fn; #difference in function evals\n",
    "        nrmd2 = dFn.T @ dFn; #|Fn|^2 = <Fn,Fn>\n",
    "        q = -(Fn.T @ dFn)/nrmd2; #quality measure q\n",
    "\n",
    "        #if verb:\n",
    "        #    print(\"q0=%1.1e, beta0 = %1.1e\" %(q,beta));\n",
    "\n",
    "        bis=0;\n",
    "        while q<0.5+eps and bis<maxbis:\n",
    "            beta=0.5*beta; #halve beta and try again\n",
    "            Fnp = f(xn+beta*dn);\n",
    "            dFn = Fnp-Fn;\n",
    "            nf+=1;\n",
    "            nrmd2 = dFn.T @ dFn; #|Fn|^2 = <Fn,Fn>\n",
    "            q = -(Fn.T @ dFn)/nrmd2; #quality measure q\n",
    "            bis+=1; #increase bisection counter\n",
    "\n",
    "    pm = beta*dn;\n",
    "    nrmpn = beta*ndn;\n",
    "    xn = xn+beta*dn;\n",
    "    Fn = Fnp;\n",
    "\n",
    "    return (xn,Fn,nrmpn,nf,beta);\n",
    "\n",
    "def broyden_method_ndLS(f,B0,x0,tol,nmax,Bmat='Id',verb=False,LS=True):\n",
    "\n",
    "    # Initialize arrays and function value\n",
    "    d = x0.shape[0];\n",
    "    xn = x0; #initial guess\n",
    "    rn = x0; #list of iterates\n",
    "    Fn = f(xn); #function value vector\n",
    "    nrmpn = 1;\n",
    "    n=0;\n",
    "    nf=1;\n",
    "\n",
    "    #linesearch parameters\n",
    "    maxbis=6; eps=1e-5;\n",
    "\n",
    "    #####################################################################\n",
    "    # Create functions to apply B0 or its inverse\n",
    "    if Bmat=='fwd':\n",
    "        #B0 is an approximation of Jf(x0)\n",
    "        # Use pivoted LU factorization to solve systems for B0. Makes lusolve O(n^2)\n",
    "        lu, piv = lu_factor(B0);\n",
    "        luT, pivT = lu_factor(B0.T);\n",
    "\n",
    "        def Bapp(x): return lu_solve((lu, piv), x); #np.linalg.solve(B0,x);\n",
    "        def BTapp(x): return lu_solve((luT, pivT), x) #np.linalg.solve(B0.T,x);\n",
    "    elif Bmat=='inv':\n",
    "        #B0 is an approximation of the inverse of Jf(x0)\n",
    "        def Bapp(x): return B0 @ x;\n",
    "        def BTapp(x): return B0.T @ x;\n",
    "    else:\n",
    "        Bmat='Id';\n",
    "        #default is the identity\n",
    "        def Bapp(x): return x;\n",
    "        def BTapp(x): return x;\n",
    "    ####################################################################\n",
    "    # Define function that applies Bapp(x)+Un*Vn.T*x depending on inputs\n",
    "    def Inapp(Bapp,Bmat,Un,Vn,x):\n",
    "        rk=Un.shape[0];\n",
    "\n",
    "        if Bmat=='Id':\n",
    "            y=x;\n",
    "        else:\n",
    "            y=Bapp(x);\n",
    "\n",
    "        if rk>0:\n",
    "            y=y+Un.T@(Vn@x);\n",
    "\n",
    "        return y;\n",
    "    #####################################################################\n",
    "\n",
    "    # Initialize low rank matrices Un and Vn\n",
    "    Un = np.zeros((0,d)); Vn=Un;\n",
    "    beta=1; type='broyden';\n",
    "\n",
    "    if verb:\n",
    "        print(\"|--n--|----xn----|---|f(xn)|---|---beta---|--------|---nfv---|\");\n",
    "\n",
    "    while nrmpn>tol and n<=nmax:\n",
    "        if verb:\n",
    "            print(\"|--%d--|%1.7f|%1.12f|%1.3f|%s|%d\" % (n,np.linalg.norm(xn),np.linalg.norm(Fn),beta,type,nf));\n",
    "\n",
    "        #Broyden step xn = xn -B_n\\Fn\n",
    "        if (n==0):\n",
    "            dn = -Inapp(Bapp,Bmat,Un,Vn,Fn);\n",
    "        elif (n==1):\n",
    "            dn = -IFnp - Un.T@(Vn@Fn);\n",
    "        else:\n",
    "            dn = -IFnp - (Vn[n-1]@Fn)*Un[n-1];\n",
    "            #dn = -Inapp(Bapp,Bmat,Un,Vn,Fn);\n",
    "\n",
    "        ########################################################\n",
    "        # Derivative-free line search. If full step is accepted (beta=1), this is\n",
    "        # equivalent to updating xn = xn + dn, Fn = fun(Fn), nrmpn = norm(pn)\n",
    "        (xn,Fn,nrmpn,nf,beta)=LS_Gw(f,xn,Fn,dn,nf,eps,maxbis,verb,LS);\n",
    "        ###########################################################\n",
    "        # Update In using only the previous I_n-1\n",
    "        #(this is equivalent to the explicit update formula)\n",
    "        IFnp = Inapp(Bapp,Bmat,Un,Vn,Fn);\n",
    "        un = (1-beta)*dn + IFnp;\n",
    "        cn = beta*dn.T @ (dn+IFnp);\n",
    "        # The end goal is to add the rank 1 u*v' update as the next columns of\n",
    "        # Vn and Un, as is done in, say, the eigendecomposition\n",
    "        Vn = np.vstack((Vn,Inapp(BTapp,Bmat,Vn,Un,beta*dn)));\n",
    "        Un = np.vstack((Un,-(1/cn)*un));\n",
    "\n",
    "        n+=1;\n",
    "        rn = np.vstack((rn,xn));\n",
    "\n",
    "    r=xn;\n",
    "\n",
    "    if verb:\n",
    "        if nrmpn>tol:\n",
    "            print(\"Broyden method failed to converge, n=%d, |F(xn)|=%1.1e\\n\" % (nmax,np.linalg.norm(Fn)));\n",
    "        else:\n",
    "            print(\"Broyden method converged, n=%d, |F(xn)|=%1.1e\\n\" % (n,np.linalg.norm(Fn)));\n",
    "\n",
    "    return(r,rn,nf)\n",
    "\n",
    "def newton_method_nd_LS(f,Jf,x0,tol,nmax,verb=False,LS=True):\n",
    "\n",
    "    # Initialize arrays and function value\n",
    "    xn = x0; #initial guess\n",
    "    rn = x0; #list of iterates\n",
    "    Fn = f(xn); #function value vector\n",
    "    n=0;\n",
    "    nf=1; nJ=0; #function and Jacobian evals\n",
    "    npn=1;\n",
    "\n",
    "    #linesearch parameters\n",
    "    maxbis=8; eps=1e-1; beta=1;\n",
    "\n",
    "    if verb:\n",
    "        print(\"|--n--|----xn----|---|f(xn)|---|--beta--|\");\n",
    "\n",
    "    while npn>tol and n<=nmax:\n",
    "        # compute n x n Jacobian matrix\n",
    "        Jn = Jf(xn);\n",
    "        nJ+=1;\n",
    "\n",
    "        if verb:\n",
    "            print(\"|--%d--|%1.7f|%1.12f|%1.3f|\" %(n,np.linalg.norm(xn),np.linalg.norm(Fn),beta));\n",
    "\n",
    "        # Newton step (we could check whether Jn is close to singular here)\n",
    "        pn = -np.linalg.solve(Jn,Fn);\n",
    "\n",
    "        ########################################################\n",
    "        # Derivative-free line search. If full step is accepted (beta=1), this is\n",
    "        # equivalent to updating xn = xn + dn, Fn = fun(Fn), nrmpn = norm(pn)\n",
    "        (xn,Fn,npn,nf,beta)=LS_Gw(f,xn,Fn,pn,nf,eps,maxbis,verb,LS);\n",
    "        ###########################################################\n",
    "\n",
    "        n+=1;\n",
    "        rn = np.vstack((rn,xn));\n",
    "\n",
    "    r=xn;\n",
    "\n",
    "    if verb:\n",
    "        if npn>tol:\n",
    "            print(\"Newton method failed to converge, n=%d, |F(xn)|=%1.1e\\n\" % (nmax,np.linalg.norm(Fn)));\n",
    "        else:\n",
    "            print(\"Newton method converged, n=%d, |F(xn)|=%1.1e\\n\" % (n,np.linalg.norm(Fn)));\n",
    "\n",
    "    return (r,rn,nf,nJ);\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# Backtracking line-search algorithm (to find an for the step xn + an*pn)\n",
    "def line_search(f,Gf,x0,p,type,mxbck,c1,c2):\n",
    "    alpha=2;\n",
    "    n=0;\n",
    "    cond=False; #condition (if True, we accept alpha)\n",
    "    f0 = f(x0); # initial function value\n",
    "    Gdotp = p.T @ Gf(x0); #initial directional derivative\n",
    "    nf=1;ng=1; # number of function and grad evaluations\n",
    "\n",
    "    # we backtrack until our conditions are met or we've halved alpha too much\n",
    "    while n<=mxbck and (not cond):\n",
    "        alpha=0.5*alpha;\n",
    "        x1 = x0+alpha*p;\n",
    "        # Armijo condition of sufficient descent. We draw a line and only accept\n",
    "        # a step if our function value is under this line.\n",
    "        Armijo = f(x1) <= f0 + c1*alpha*Gdotp;\n",
    "        nf+=1;\n",
    "        if type=='wolfe':\n",
    "            #Wolfe (Armijo sufficient descent and simple curvature conditions)\n",
    "            # that is, the slope at new point is lower\n",
    "            Curvature = p.T @ Gf(x1) >= c2*Gdotp;\n",
    "            # condition is sufficient descent AND slope reduction\n",
    "            cond = Armijo and Curvature;\n",
    "            ng+=1;\n",
    "        elif type=='swolfe':\n",
    "            #Symmetric Wolfe (Armijo and symmetric curvature)\n",
    "            # that is, the slope at new point is lower in absolute value\n",
    "            Curvature = np.abs(p.T @ Gf(x1)) <= c2*np.abs(Gdotp);\n",
    "            # condition is sufficient descent AND symmetric slope reduction\n",
    "            cond = Armijo and Curvature;\n",
    "            ng+=1;\n",
    "        else:\n",
    "            # Default is Armijo only (sufficient descent)\n",
    "            cond = Armijo;\n",
    "\n",
    "        n+=1;\n",
    "\n",
    "    return(x1,alpha,nf,ng);\n",
    "\n",
    "################################################################################\n",
    "# Steepest descent algorithm\n",
    "def steepest_descent(f,Gf,x0,tol,nmax,type='swolfe',verb=True):\n",
    "    # Set linesearch parameters\n",
    "    c1=1e-3; c2=0.9; mxbck=10;\n",
    "    # Initialize alpha, fn and pn\n",
    "    alpha=1;\n",
    "    xn = x0; #current iterate\n",
    "    rn = x0; #list of iterates\n",
    "    fn = f(xn); nf=1; #function eval\n",
    "    pn = -Gf(xn); ng=1; #gradient eval\n",
    "\n",
    "    # if verb is true, prints table of results\n",
    "    if verb:\n",
    "        print(\"|--n--|-alpha-|----|xn|----|---|f(xn)|---|---|Gf(xn)|---|\");\n",
    "\n",
    "    # while the size of the step is > tol and n less than nmax\n",
    "    n=0;\n",
    "    while n<=nmax and np.linalg.norm(pn)>tol:\n",
    "        if verb:\n",
    "            print(\"|--%d--|%1.5f|%1.7f|%1.7f|%1.7f|\" %(n,alpha,np.linalg.norm(xn),np.abs(fn),np.linalg.norm(pn)));\n",
    "\n",
    "        # Use line_search to determine a good alpha, and new step xn = xn + alpha*pn\n",
    "        (xn,alpha,nfl,ngl)=line_search(f,Gf,xn,pn,type,mxbck,c1,c2);\n",
    "\n",
    "        nf=nf+nfl; ng=ng+ngl; #update function and gradient eval counts\n",
    "        fn = f(xn); #update function evaluation\n",
    "        pn = -Gf(xn); # update gradient evaluation\n",
    "        n+=1;\n",
    "        rn=np.vstack((rn,xn)); #add xn to list of iterates\n",
    "\n",
    "    r = xn; # approx root is last iterate\n",
    "\n",
    "    return (r,rn,nf,ng);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc6e7b2c-6507-4391-b054-729eb4fe522b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0 = [1,1]=================================\n",
      "Newton: converges to [-1.81626407  0.8373678 ] in 9\n",
      "Lazy: no convergence\n",
      "Broyden: converges to [ 1.00416874 -1.72963729] in 22\n",
      "x0 = [1,-1]=================================\n",
      "Newton: converges to [ 1.00416874 -1.72963729] in 7\n",
      "Lazy: converges to [ 1.00416874 -1.72963729] in 38\n",
      "Broyden: converges to [ 1.00416874 -1.72963729] in 15\n",
      "x0 = [0,0]=================================\n",
      "Newton: no convergence\n",
      "Lazy: no convergence\n",
      "Broyden: converges to [-1.81626407  0.8373678 ] in 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajpat\\AppData\\Local\\Temp\\ipykernel_27368\\330315352.py:4: RuntimeWarning: overflow encountered in exp\n",
      "  return np.array([x**2 + y**2 - 4, np.exp(x)+y-1])\n",
      "C:\\Users\\ajpat\\AppData\\Local\\Temp\\ipykernel_27368\\2794652872.py:53: LinAlgWarning: Diagonal number 2 is exactly zero. Singular matrix.\n",
      "  lu, piv = lu_factor(Jn);\n"
     ]
    }
   ],
   "source": [
    "# Problem 1\n",
    "def F(X):\n",
    "    x = X[0]\n",
    "    y = X[1]\n",
    "    return np.array([x**2 + y**2 - 4, np.exp(x)+y-1])\n",
    "\n",
    "def Jf(x):\n",
    "    return np.array([[2*x[0], 2*x[1]],[np.exp(x[0]),1]])\n",
    "\n",
    "\n",
    "\n",
    "    # Apply Newton Method:\n",
    "x0 = np.array([1,1]); tol=1e-10; nmax=100;\n",
    "B0 = Jf(x0)\n",
    "\n",
    "nmax = 250\n",
    "tol = 1e-10\n",
    "print(\"x0 = [1,1]=================================\")\n",
    "try:\n",
    "    (rNewt1,rnNewt1,nfNewt1,nJNewt1) = newton_method_nd(F,Jf,x0,tol,nmax)\n",
    "    print(f'Newton: converges to {rNewt1} in {nfNewt1}')\n",
    "except ValueError:\n",
    "    print('Newton: no convergence')\n",
    "\n",
    "try:\n",
    "    (rLazy1,rnLazy1,nfLazy1,nJLazy1) = lazy_newton_method_nd(F,Jf,x0,tol,nmax)\n",
    "    print(f'Lazy: converges to {rLazy1} in {nfLazy1}')\n",
    "except ValueError:\n",
    "    print('Lazy: no convergence')\n",
    "    \n",
    "try:\n",
    "    (rBroy1,rnBroy1,nfBroy1) = broyden_method_nd(F,B0,x0,tol,nmax,Bmat='Id',verb=False)\n",
    "    print(f'Broyden: converges to {rBroy1} in {nfBroy1}')\n",
    "except ValueError:\n",
    "    print('Broyden: no convergence')\n",
    "except RuntimeWarning:\n",
    "    print('Broyden: no convergence')\n",
    "\n",
    "\n",
    "x0 = np.array([1,-1]); \n",
    "B0 = Jf(x0)\n",
    "print(\"x0 = [1,-1]=================================\")\n",
    "try:\n",
    "    (rNewt2,rnNewt2,nfNewt2,nJNewt2) = newton_method_nd(F,Jf,x0,tol,nmax)\n",
    "    print(f'Newton: converges to {rNewt2} in {nfNewt2}')\n",
    "except ValueError:\n",
    "    print('Newton: no convergence')\n",
    "\n",
    "try:\n",
    "    (rLazy2,rnLazy2,nfLazy2,nJLazy2) = lazy_newton_method_nd(F,Jf,x0,tol,nmax)\n",
    "    print(f'Lazy: converges to {rLazy2} in {nfLazy2}')\n",
    "except ValueError:\n",
    "    print('Lazy: no convergence')\n",
    "    \n",
    "try:\n",
    "    (rBroy2,rnBroy2,nfBroy2) = broyden_method_nd(F,B0,x0,tol,nmax,Bmat='Id',verb=False)\n",
    "    print(f'Broyden: converges to {rBroy2} in {nfBroy2}')\n",
    "except ValueError:\n",
    "    print('Broyden: no convergence')\n",
    "except RuntimeWarning:\n",
    "    print('Broyden: no convergence')\n",
    "\n",
    "\n",
    "x0 = np.array([0,0]); \n",
    "B0 = Jf(x0)\n",
    "print(\"x0 = [0,0]=================================\")\n",
    "try:\n",
    "    (rNewt3,rnNewt3,nfNewt3,nJNewt3) = newton_method_nd(F,Jf,x0,tol,nmax)\n",
    "    print(f'Newton: converges to {rNewt3} in {nfNewt3}')\n",
    "except ValueError:\n",
    "    print('Newton: no convergence')\n",
    "\n",
    "try:\n",
    "    (rLazy3,rnLazy3,nfLazy3,nJLazy3) = lazy_newton_method_nd(F,Jf,x0,tol,nmax)\n",
    "    print(f'Lazy: converges to {rLazy3} in {nfLazy3}')\n",
    "except ValueError:\n",
    "    print('Lazy: no convergence')\n",
    "    \n",
    "try:\n",
    "    (rBroy3,rnBroy3,nfBroy3) = broyden_method_nd(F,B0,x0,tol,nmax,Bmat='Id',verb=False)\n",
    "    print(f'Broyden: converges to {rBroy3} in {nfBroy3}')\n",
    "except ValueError:\n",
    "    print('Broyden: no convergence')\n",
    "except RuntimeWarning:\n",
    "    print('Broyden: no convergence')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "89cb8dca-f46e-4471-a6b7-bc6b9b0581c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newton's Method\n",
      "|--n--|----xn----|---|f(xn)|---|\n",
      "|--0--|0.0000000|1.000000000000|\n",
      "|--1--|1.0096729|0.052502296766|\n",
      "|--2--|1.0189865|0.003928080497|\n",
      "|--3--|1.0150555|0.000018258813|\n",
      "|--4--|1.0150372|0.000000149852|\n",
      "Newton method converged, n=5, |F(xn)|=6.6e-10\n",
      "\n",
      "Steepest Descent:\n",
      "|--n--|-alpha-|----|xn|----|---|f(xn)|---|---|Gf(xn)|---|\n",
      "|--0--|1.00000|0.0000000|0.5000000|1.0000500|\n",
      "|--1--|1.00000|1.0000500|0.0040505|0.0928436|\n",
      "|--2--|1.00000|1.0017585|0.0003679|0.0290200|\n",
      "|--3--|1.00000|1.0151703|0.0000272|0.0081035|\n",
      "|--4--|1.00000|1.0141247|0.0000026|0.0025049|\n",
      "|--5--|1.00000|1.0150985|0.0000002|0.0007192|\n",
      "|--6--|1.00000|1.0149681|0.0000000|0.0002217|\n",
      "|--7--|1.00000|1.0150459|0.0000000|0.0000649|\n",
      "|--8--|1.00000|1.0150316|0.0000000|0.0000199|\n",
      "|--9--|1.00000|1.0150380|0.0000000|0.0000059|\n",
      "|--10--|1.00000|1.0150366|0.0000000|0.0000018|\n",
      "Steepest descent converged, n =  12  , |F(xn)| =  4.740974410040649e-07\n",
      " \n",
      "Hybrid Method\n",
      "|--n--|-alpha-|----|xn|----|---|f(xn)|---|---|Gf(xn)|---|\n",
      "|--0--|1.00000|0.0000000|0.5000000|1.0000500|\n",
      "|--1--|1.00000|1.0000500|0.0040505|0.0928436|\n",
      "|--n--|----xn----|---|f(xn)|---|\n",
      "|--0--|1.0017585|0.027124869040|\n",
      "Newton method converged, n=1, |F(xn)|=5.5e-04\n",
      "\n",
      "Hybrid method converged with n =  5  , |F(xn)| =  0.0005456180298549902\n"
     ]
    }
   ],
   "source": [
    "# Problem 2\n",
    "def F(X):\n",
    "    x = X[0]\n",
    "    y = X[1]\n",
    "    z = X[2]\n",
    "    return np.array([x+np.cos(x*y*z)-1,(1-x)**0.25+y+0.05*z**2-0.15*z-1,-x**2-0.1*y+z-1])\n",
    "\n",
    "def Jf(X):\n",
    "    x = X[0]\n",
    "    y = X[1]\n",
    "    z = X[2]\n",
    "    return np.array([[1-y*z*np.sin(x*y*z),-x*y*np.sin(x*y*z),-x*y*np.sin(x*y*z)],[-0.25*(1-x)**-0.75,1,0.1*z-0.15],[-2*x,-0.2*y+0.01,1]])\n",
    "\n",
    "x0 = np.array([0,0,0])\n",
    "B0 = Jf(x0)\n",
    "nmax = 250\n",
    "tol = 1e-6\n",
    "\n",
    "print(\"Newton's Method\")\n",
    "# Newton's Method to Minimize\n",
    "(rNewt,rnNewt,nfNewt,nJNewt) = newton_method_nd(F,Jf,x0,tol,nmax,True)\n",
    "\n",
    "# Gradient Descent to Minimize\n",
    "    #Gradient of q.\n",
    "\n",
    "\n",
    "    # Define quadratic function and its gradient based on (F,JF)\n",
    "def q(x):\n",
    "    Fun = F(x);\n",
    "    return 0.5*(Fun[0]**2 + Fun[1]**2 + Fun[2]**2);\n",
    "\n",
    "def Gq(x):\n",
    "    Jfun = Jf(x);\n",
    "    Ffun = F(x);\n",
    "    return np.transpose(Jfun)@Ffun;\n",
    "\n",
    "print(\"Steepest Descent:\")\n",
    "    # Apply steepest descent:\n",
    "(r,rn,nf,ng)=steepest_descent(q,Gq,x0,tol,nmax)\n",
    "print(\"Steepest descent converged, n = \", len(rn),\" , |F(xn)| = \", np.linalg.norm(F(r)))\n",
    "\n",
    "print(\" \")\n",
    "print(\"Hybrid Method\")\n",
    "# Steepest descent then Newton's Method\n",
    "tol = 5e-2\n",
    "(r,rn,nf,ng)=steepest_descent(q,Gq,x0,tol,nmax)\n",
    "(rNewt,rnNewt,nfNewt,nJNewt) = newton_method_nd(F,Jf,r,tol,nmax,True)\n",
    "print(\"Hybrid method converged with n = \", (len(rn)+len(rnNewt)),\" , |F(xn)| = \", np.linalg.norm(F(rNewt)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d123ad-56ba-47ed-8fda-8896d2de330d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
